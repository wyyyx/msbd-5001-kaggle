{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "TrainData = pd.read_csv(\"5001train.csv\")\n",
    "TestData  = pd.read_csv(\"5001test.csv\")\n",
    "from pandas.core.frame import DataFrame\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# supposed maximal n_jobs is 16\n",
    "for i in range(400):\n",
    "    if TrainData['n_jobs'][i] == -1:\n",
    "        TrainData['n_jobs'][i] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399 [0.5287737846374512, 3.108427047729492, 0.3647949695587158, 1.022508144378662, 0.716839075088501, 12.551417112350464, 2.380812168121338, 5.002321004867554, 0.8260650634765625, 3.179537296295166, 2.6557888984680176, 1.1288769245147705, 0.8204910755157471, 3.0569889545440674, 1.7499809265136719, 0.10687422752380371, 1.5837430953979492, 0.41169190406799316, 1.44844388961792, 4.019684076309204, 0.10852193832397461, 0.4156479835510254, 0.6117250919342041, 0.6210618019104004, 2.3756959438323975, 0.5251290798187256, 2.159442186355591, 0.4118032455444336, 1.2265751361846924, 2.869878053665161, 1.6649539470672607, 0.5180611610412598, 0.20778799057006836, 5.014949798583984, 0.7200651168823242, 1.962796926498413, 5.246016979217529, 0.20919394493103027, 19.081645965576172, 0.10424518585205078, 11.385681867599487, 3.3038699626922607, 0.718425989151001, 0.4190359115600586, 0.6203067302703857, 2.5779459476470947, 5.815141916275024, 15.309467792510986, 19.17103624343872, 0.10719680786132812, 5.00507116317749, 1.8415708541870117, 5.388819217681885, 0.7342128753662109, 0.5086240768432617, 9.475033044815063, 2.567985773086548, 0.41889286041259766, 4.5985729694366455, 0.827023983001709, 2.6573989391326904, 0.954636812210083, 2.159210205078125, 1.129885196685791, 2.372515916824341, 0.7112457752227783, 3.7353639602661133, 0.4122428894042969, 1.6252388954162598, 0.416837215423584, 2.146394968032837, 0.4704749584197998, 11.761623859405518, 0.8776919841766357, 0.30509495735168457, 8.615908861160278, 12.877722978591919, 2.2035341262817383, 2.6750540733337402, 1.3669440746307373, 0.817755937576294, 10.2119779586792, 3.555359363555908, 1.5365447998046875, 9.573163032531738, 0.20435190200805664, 1.4710490703582764, 0.3158578872680664, 3.065490961074829, 0.8178892135620117, 1.4447178840637207, 1.4396169185638428, 1.9482769966125488, 0.6165080070495605, 1.3297488689422607, 0.6176338195800781, 4.706434011459351, 8.302245140075684, 0.21509289741516113, 1.7418642044067383, 1.6520798206329346, 2.986415147781372, 3.1944079399108887, 5.3138251304626465, 1.3351352214813232, 1.4419503211975098, 0.7198970317840576, 0.6438450813293457, 4.3796257972717285, 1.0214860439300537, 1.025376796722412, 0.0809779167175293, 0.13602995872497559, 1.032135248184204, 2.0716569423675537, 9.87890076637268, 4.000591039657593, 2.7595362663269043, 7.036646127700806, 14.604634046554565, 1.7414839267730713, 0.7126550674438477, 1.4421629905700684, 2.1590750217437744, 0.5096280574798584, 5.222800970077515, 15.920392990112305, 0.8229660987854004, 0.32737016677856445, 8.031869888305664, 2.2402501106262207, 2.248049259185791, 0.7174530029296875, 7.361464023590088, 3.2976667881011963, 0.12568306922912598, 3.5763561725616455, 8.04139518737793, 4.6076648235321045, 0.6966331005096436, 4.424465179443359, 14.82671594619751, 5.488461971282959, 1.4312798976898193, 0.6605172157287598, 0.51416015625, 12.894047975540161, 6.36352801322937, 0.4164550304412842, 1.0421020984649658, 0.3279411792755127, 0.5208020210266113, 2.1685738563537598, 1.036902904510498, 0.3159627914428711, 2.0618529319763184, 13.949808120727539, 1.3354160785675049, 1.8424901962280273, 0.12389111518859863, 0.12444210052490234, 2.069843053817749, 6.5232250690460205, 0.10428786277770996, 1.8548040390014648, 14.349869012832642, 4.339169025421143, 0.5142171382904053, 11.868890762329102, 4.827401876449585, 1.408696174621582, 4.910968780517578, 2.5086758136749268, 13.690213918685913, 5.316067695617676, 0.41053104400634766, 2.6623270511627197, 9.872227191925049, 21.500651121139526, 6.650718927383423, 2.067293882369995, 1.1401262283325195, 0.8254349231719971, 5.297055959701538, 5.711073160171509, 9.502803087234497, 9.181822776794434, 3.2727057933807373, 2.455394983291626, 1.4373340606689453, 0.4127051830291748, 0.9210929870605469, 2.0418319702148438, 1.3330790996551514, 3.870767116546631, 2.139227867126465, 3.059083938598633, 0.7742190361022949, 2.6891238689422607, 2.596349000930786, 2.985422134399414, 0.31214475631713867, 3.516152858734131, 1.231017827987671, 2.2468998432159424, 2.3421037197113037, 1.3591980934143066, 1.5336151123046875, 1.3337578773498535, 0.18099284172058105, 1.0214447975158691, 0.6315121650695801, 2.1524951457977295, 2.245651960372925, 36.82856607437134, 15.510921955108643, 1.0305747985839844, 7.047455549240112, 0.31667590141296387, 0.6750738620758057, 2.3760130405426025, 2.2800161838531494, 9.927421808242798, 3.6991829872131348, 19.93153977394104, 1.5579063892364502, 1.179412841796875, 1.2822511196136475, 3.9487318992614746, 0.7302792072296143, 0.5213570594787598, 5.94364595413208, 5.653739929199219, 17.408305883407593, 0.10616087913513184, 5.672400951385498, 0.20756316184997559, 0.4895312786102295, 10.465802907943726, 1.8285212516784668, 4.3022520542144775, 11.741996049880981, 6.526199102401733, 3.2674338817596436, 3.775315761566162, 1.2227509021759033, 3.9019429683685303, 0.41232895851135254, 1.6346700191497803, 2.153658866882324, 6.009807109832764, 1.2283480167388916, 4.893051862716675, 14.422080039978027, 1.7355022430419922, 6.1419878005981445, 0.5097520351409912, 4.120248079299927, 1.3346049785614014, 3.831860065460205, 7.733136892318726, 1.8557970523834229, 0.31178975105285645, 0.5005607604980469, 1.135085105895996, 0.925347089767456, 1.6470201015472412, 1.2428309917449951, 0.6469020843505859, 1.3097951412200928, 3.8121490478515625, 0.11278223991394043, 1.3541018962860107, 9.03854489326477, 7.551203966140747, 1.9744081497192383, 1.3454678058624268, 0.3170158863067627, 1.6614341735839844, 2.8109166622161865, 2.5708351135253906, 1.0699238777160645, 0.6166501045227051, 1.047494888305664, 6.396213054656982, 4.828541040420532, 0.2683711051940918, 3.167243003845215, 14.3997061252594, 5.261759996414185, 1.4261538982391357, 1.3182392120361328, 7.980163097381592, 0.615811824798584, 3.264382839202881, 1.6355979442596436, 0.41790080070495605, 3.8750181198120117, 11.553821086883545, 0.3140449523925781, 24.57223391532898, 3.422435998916626, 1.9529969692230225, 2.6479880809783936, 0.9741051197052002, 1.0936822891235352, 15.562372207641602, 1.4355058670043945, 0.5180830955505371, 13.05526089668274, 0.24338006973266602, 0.9221570491790771, 0.617988109588623, 0.16934800148010254, 0.4866461753845215, 0.40978288650512695, 3.9722681045532227, 4.713926315307617, 0.418626070022583, 6.5072832107543945, 30.76228404045105, 1.6323328018188477, 7.682777166366577, 0.4112668037414551, 0.8704860210418701, 0.13311195373535156, 16.13510012626648, 0.204240083694458, 0.10599493980407715, 0.19428682327270508, 0.5145440101623535, 0.40667271614074707, 0.10724401473999023, 1.2486259937286377, 0.10421609878540039, 2.9610602855682373, 38.380277156829834, 0.31032586097717285, 0.5930180549621582, 4.541189908981323, 5.416004180908203, 3.688526153564453, 0.4315299987792969, 0.2048499584197998, 0.7740991115570068, 1.1618578433990479, 9.008701086044312, 21.102274179458618, 0.5115048885345459, 2.3389854431152344, 13.521346092224121, 10.501068115234375, 1.320350170135498, 1.057945728302002, 4.000926971435547, 3.1598689556121826, 5.837935924530029, 4.963228940963745, 1.675260305404663, 3.8172101974487305, 0.6353790760040283, 4.103880882263184, 0.29339599609375, 3.6535580158233643, 1.1227059364318848, 0.5163500308990479, 1.2217209339141846, 0.21878719329833984, 0.519719123840332, 1.2396180629730225, 0.2091069221496582, 4.980291843414307, 2.779540777206421, 7.536048889160156, 4.067412853240967, 6.223984956741333, 16.65813684463501, 5.079465866088867, 0.2081890106201172, 0.9445061683654785, 0.43259429931640625, 21.342159748077393, 0.8225290775299072, 0.8321709632873535, 2.8498401641845703, 0.4657630920410156, 6.516363859176636, 0.5179357528686523, 3.4649930000305176, 5.615211009979248, 0.20357823371887207, 9.808586120605469, 0.10647797584533691, 4.172821998596191, 1.6479690074920654, 1.3367772102355957, 4.678377866744995, 2.285008192062378, 2.1850461959838867, 0.28858304023742676]\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for i in  range(0, 400):\n",
    "    X1,Y1=make_classification(n_samples = TrainData.iat[i,7], n_features= TrainData.iat[i,8] , n_classes = TrainData.iat[i,9]  , n_clusters_per_class = TrainData.iat[i,10] ,n_informative = TrainData.iat[i,11], flip_y= TrainData.iat[i,12] , scale= TrainData.iat[i,13])\n",
    "    import time\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    clf = SGDClassifier(penalty = TrainData.iat[i,1], l1_ratio = TrainData.iat[i,2], alpha = TrainData.iat[i,3], max_iter = TrainData.iat[i,4], random_state = TrainData.iat[i,5], n_jobs = TrainData.iat[i,6])\n",
    "    start = time.time()  \n",
    "    clf.fit(X1, Y1)\n",
    "    elapsed = (time.time() - start)\n",
    "    result.append(elapsed)  \n",
    "print(i,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "TrainData['time_pre']=result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData1 = pd.get_dummies(TrainData, columns = ['penalty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "f=pd.DataFrame({\"id\":TrainData['id'], \"time\":TrainData['time'],\"time_pred\":TrainData1['time_pre']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData2 = TrainData1[['l1_ratio' , 'alpha' , 'max_iter' , 'n_jobs' , 'n_samples' , 'n_features' , 'n_classes' , 'n_clusters_per_class'  , 'flip_y' , 'scale', 'time_pre', 'penalty_elasticnet', 'penalty_l1','penalty_l2','penalty_none']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData2=TrainData2.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, activation=\"relu\", units=1000, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1000, units=1, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(output_dim=1000, input_dim=15, init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(output_dim=1, input_dim=1000,init='uniform'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    if TestData['n_jobs'][i] == -1:\n",
    "        TestData['n_jobs'][i] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 [1.8439350128173828, 15.163701057434082, 0.9275729656219482, 2.476964235305786, 3.417428970336914, 13.073661804199219, 2.782838821411133, 1.0379631519317627, 12.739984035491943, 0.49919795989990234, 5.460515975952148, 42.91088795661926, 1.1511502265930176, 23.30795693397522, 0.15194082260131836, 0.7323782444000244, 1.0313589572906494, 9.477136135101318, 2.778496026992798, 2.071234941482544, 0.3114309310913086, 0.3738260269165039, 0.7225978374481201, 0.822598934173584, 2.047658920288086, 3.295024871826172, 1.657109022140503, 9.006521224975586, 1.4531900882720947, 2.6983988285064697, 18.56486225128174, 2.9110682010650635, 1.348106861114502, 6.547025918960571, 16.632874011993408, 1.1218318939208984, 5.332128047943115, 4.603480100631714, 1.3356549739837646, 2.2984557151794434, 9.739620685577393, 8.502506017684937, 1.4415867328643799, 14.61195993423462, 1.2290401458740234, 1.5208640098571777, 5.639392137527466, 1.3312718868255615, 9.06163477897644, 1.9462080001831055, 0.321505069732666, 35.94034814834595, 0.20817899703979492, 11.545248985290527, 15.8230881690979, 0.3615708351135254, 2.146862745285034, 2.767315149307251, 0.7851979732513428, 1.632694959640503, 1.5371499061584473, 7.0361762046813965, 0.8644506931304932, 25.48219609260559, 4.2877771854400635, 43.98281002044678, 1.0205600261688232, 1.1273510456085205, 13.343456745147705, 1.6444177627563477, 0.514214038848877, 1.0223841667175293, 9.06658387184143, 0.3621339797973633, 10.818181991577148, 5.711242914199829, 2.565432071685791, 5.303907155990601, 6.753381967544556, 1.4557859897613525, 20.973562002182007, 6.451974868774414, 8.1942880153656, 1.8331866264343262, 1.1224017143249512, 5.3207409381866455, 13.93629503250122, 0.5308873653411865, 4.258373975753784, 1.1439309120178223, 3.6245789527893066, 1.2006959915161133, 2.0579540729522705, 25.60652208328247, 8.702075719833374, 4.688421964645386, 39.07152271270752, 0.5103850364685059, 0.9161510467529297, 0.11409807205200195]\n"
     ]
    }
   ],
   "source": [
    "result2=[]\n",
    "for i in  range(0, 100):\n",
    "    X2,Y2=make_classification(n_samples = TestData.iat[i,7], n_features= TestData.iat[i,8] , n_classes = TestData.iat[i,9]  , n_clusters_per_class = TestData.iat[i,10] ,n_informative = TestData.iat[i,11], flip_y= TestData.iat[i,12] , scale= TestData.iat[i,13])\n",
    "    import time\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    clf = SGDClassifier(penalty = TestData.iat[i,1], l1_ratio = TestData.iat[i,2], alpha = TestData.iat[i,3], max_iter = TestData.iat[i,4], random_state = TestData.iat[i,5], n_jobs = TestData.iat[i,6])\n",
    "    start = time.time()  \n",
    "    clf.fit(X2, Y2)\n",
    "    elapsed = (time.time() - start)\n",
    "    result2.append(elapsed)  \n",
    "print(i,result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "TestData['time_pre']=result2\n",
    "TestData1 = pd.get_dummies(TestData, columns = ['penalty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestData2 = TestData1[['l1_ratio' , 'alpha' , 'max_iter'  , 'n_jobs' , 'n_samples' , 'n_features' , 'n_classes' , 'n_clusters_per_class' , 'flip_y' , 'scale', 'time_pre', 'penalty_elasticnet', 'penalty_l1','penalty_l2','penalty_none']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestData2=TestData2.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/170\n",
      " - 1s - loss: 31.0759\n",
      "Epoch 2/170\n",
      " - 0s - loss: 22.3228\n",
      "Epoch 3/170\n",
      " - 0s - loss: 17.4108\n",
      "Epoch 4/170\n",
      " - 0s - loss: 14.4176\n",
      "Epoch 5/170\n",
      " - 0s - loss: 12.8485\n",
      "Epoch 6/170\n",
      " - 0s - loss: 11.0749\n",
      "Epoch 7/170\n",
      " - 0s - loss: 9.5734\n",
      "Epoch 8/170\n",
      " - 0s - loss: 8.1777\n",
      "Epoch 9/170\n",
      " - 0s - loss: 7.0753\n",
      "Epoch 10/170\n",
      " - 0s - loss: 6.3414\n",
      "Epoch 11/170\n",
      " - 0s - loss: 5.3771\n",
      "Epoch 12/170\n",
      " - 0s - loss: 4.8046\n",
      "Epoch 13/170\n",
      " - 0s - loss: 3.9761\n",
      "Epoch 14/170\n",
      " - 0s - loss: 3.5471\n",
      "Epoch 15/170\n",
      " - 0s - loss: 3.2372\n",
      "Epoch 16/170\n",
      " - 0s - loss: 2.7641\n",
      "Epoch 17/170\n",
      " - 0s - loss: 2.5691\n",
      "Epoch 18/170\n",
      " - 0s - loss: 2.4304\n",
      "Epoch 19/170\n",
      " - 0s - loss: 2.2635\n",
      "Epoch 20/170\n",
      " - 0s - loss: 1.8990\n",
      "Epoch 21/170\n",
      " - 0s - loss: 1.8953\n",
      "Epoch 22/170\n",
      " - 0s - loss: 1.4847\n",
      "Epoch 23/170\n",
      " - 0s - loss: 1.4953\n",
      "Epoch 24/170\n",
      " - 0s - loss: 1.5399\n",
      "Epoch 25/170\n",
      " - 0s - loss: 1.4497\n",
      "Epoch 26/170\n",
      " - 0s - loss: 1.3343\n",
      "Epoch 27/170\n",
      " - 0s - loss: 1.3470\n",
      "Epoch 28/170\n",
      " - 0s - loss: 1.0368\n",
      "Epoch 29/170\n",
      " - 0s - loss: 1.0837\n",
      "Epoch 30/170\n",
      " - 0s - loss: 1.1352\n",
      "Epoch 31/170\n",
      " - 0s - loss: 1.0462\n",
      "Epoch 32/170\n",
      " - 0s - loss: 1.0131\n",
      "Epoch 33/170\n",
      " - 0s - loss: 1.0291\n",
      "Epoch 34/170\n",
      " - 0s - loss: 0.9521\n",
      "Epoch 35/170\n",
      " - 0s - loss: 0.8615\n",
      "Epoch 36/170\n",
      " - 0s - loss: 0.9474\n",
      "Epoch 37/170\n",
      " - 0s - loss: 1.0119\n",
      "Epoch 38/170\n",
      " - 0s - loss: 0.8933\n",
      "Epoch 39/170\n",
      " - 0s - loss: 0.7764\n",
      "Epoch 40/170\n",
      " - 0s - loss: 0.8138\n",
      "Epoch 41/170\n",
      " - 0s - loss: 0.6859\n",
      "Epoch 42/170\n",
      " - 0s - loss: 0.7469\n",
      "Epoch 43/170\n",
      " - 0s - loss: 0.7694\n",
      "Epoch 44/170\n",
      " - 0s - loss: 0.8024\n",
      "Epoch 45/170\n",
      " - 0s - loss: 0.7131\n",
      "Epoch 46/170\n",
      " - 0s - loss: 0.6681\n",
      "Epoch 47/170\n",
      " - 0s - loss: 0.6628\n",
      "Epoch 48/170\n",
      " - 0s - loss: 0.7186\n",
      "Epoch 49/170\n",
      " - 0s - loss: 0.6888\n",
      "Epoch 50/170\n",
      " - 0s - loss: 0.6401\n",
      "Epoch 51/170\n",
      " - 0s - loss: 0.7207\n",
      "Epoch 52/170\n",
      " - 0s - loss: 0.6193\n",
      "Epoch 53/170\n",
      " - 0s - loss: 0.6379\n",
      "Epoch 54/170\n",
      " - 0s - loss: 0.7090\n",
      "Epoch 55/170\n",
      " - 0s - loss: 0.6214\n",
      "Epoch 56/170\n",
      " - 0s - loss: 0.6168\n",
      "Epoch 57/170\n",
      " - 0s - loss: 0.5614\n",
      "Epoch 58/170\n",
      " - 0s - loss: 0.6488\n",
      "Epoch 59/170\n",
      " - 0s - loss: 0.5653\n",
      "Epoch 60/170\n",
      " - 0s - loss: 0.5667\n",
      "Epoch 61/170\n",
      " - 0s - loss: 0.5286\n",
      "Epoch 62/170\n",
      " - 0s - loss: 0.6572\n",
      "Epoch 63/170\n",
      " - 0s - loss: 0.6931\n",
      "Epoch 64/170\n",
      " - 0s - loss: 0.5205\n",
      "Epoch 65/170\n",
      " - 0s - loss: 0.4749\n",
      "Epoch 66/170\n",
      " - 0s - loss: 0.4900\n",
      "Epoch 67/170\n",
      " - 0s - loss: 0.4793\n",
      "Epoch 68/170\n",
      " - 0s - loss: 0.5183\n",
      "Epoch 69/170\n",
      " - 0s - loss: 0.5343\n",
      "Epoch 70/170\n",
      " - 0s - loss: 0.4870\n",
      "Epoch 71/170\n",
      " - 0s - loss: 0.4428\n",
      "Epoch 72/170\n",
      " - 0s - loss: 0.4789\n",
      "Epoch 73/170\n",
      " - 0s - loss: 0.4631\n",
      "Epoch 74/170\n",
      " - 0s - loss: 0.4795\n",
      "Epoch 75/170\n",
      " - 0s - loss: 0.5585\n",
      "Epoch 76/170\n",
      " - 0s - loss: 0.4365\n",
      "Epoch 77/170\n",
      " - 0s - loss: 0.4719\n",
      "Epoch 78/170\n",
      " - 0s - loss: 0.4414\n",
      "Epoch 79/170\n",
      " - 0s - loss: 0.4769\n",
      "Epoch 80/170\n",
      " - 0s - loss: 0.4053\n",
      "Epoch 81/170\n",
      " - 0s - loss: 0.4308\n",
      "Epoch 82/170\n",
      " - 0s - loss: 0.4312\n",
      "Epoch 83/170\n",
      " - 0s - loss: 0.4251\n",
      "Epoch 84/170\n",
      " - 0s - loss: 0.3992\n",
      "Epoch 85/170\n",
      " - 0s - loss: 0.3985\n",
      "Epoch 86/170\n",
      " - 0s - loss: 0.4123\n",
      "Epoch 87/170\n",
      " - 0s - loss: 0.3888\n",
      "Epoch 88/170\n",
      " - 0s - loss: 0.3936\n",
      "Epoch 89/170\n",
      " - 0s - loss: 0.3610\n",
      "Epoch 90/170\n",
      " - 0s - loss: 0.5586\n",
      "Epoch 91/170\n",
      " - 0s - loss: 0.3877\n",
      "Epoch 92/170\n",
      " - 0s - loss: 0.4100\n",
      "Epoch 93/170\n",
      " - 0s - loss: 0.4209\n",
      "Epoch 94/170\n",
      " - 0s - loss: 0.3489\n",
      "Epoch 95/170\n",
      " - 0s - loss: 0.3866\n",
      "Epoch 96/170\n",
      " - 0s - loss: 0.4125\n",
      "Epoch 97/170\n",
      " - 0s - loss: 0.3416\n",
      "Epoch 98/170\n",
      " - 0s - loss: 0.2899\n",
      "Epoch 99/170\n",
      " - 0s - loss: 0.3749\n",
      "Epoch 100/170\n",
      " - 0s - loss: 0.4144\n",
      "Epoch 101/170\n",
      " - 0s - loss: 0.3156\n",
      "Epoch 102/170\n",
      " - 0s - loss: 0.3124\n",
      "Epoch 103/170\n",
      " - 0s - loss: 0.3447\n",
      "Epoch 104/170\n",
      " - 0s - loss: 0.3102\n",
      "Epoch 105/170\n",
      " - 0s - loss: 0.3293\n",
      "Epoch 106/170\n",
      " - 0s - loss: 0.2612\n",
      "Epoch 107/170\n",
      " - 0s - loss: 0.2733\n",
      "Epoch 108/170\n",
      " - 0s - loss: 0.3111\n",
      "Epoch 109/170\n",
      " - 0s - loss: 0.3326\n",
      "Epoch 110/170\n",
      " - 0s - loss: 0.3505\n",
      "Epoch 111/170\n",
      " - 0s - loss: 0.2679\n",
      "Epoch 112/170\n",
      " - 0s - loss: 0.3251\n",
      "Epoch 113/170\n",
      " - 0s - loss: 0.3222\n",
      "Epoch 114/170\n",
      " - 0s - loss: 0.2546\n",
      "Epoch 115/170\n",
      " - 0s - loss: 0.3400\n",
      "Epoch 116/170\n",
      " - 0s - loss: 0.3345\n",
      "Epoch 117/170\n",
      " - 0s - loss: 0.3020\n",
      "Epoch 118/170\n",
      " - 0s - loss: 0.3228\n",
      "Epoch 119/170\n",
      " - 0s - loss: 0.3551\n",
      "Epoch 120/170\n",
      " - 0s - loss: 0.3335\n",
      "Epoch 121/170\n",
      " - 0s - loss: 0.2722\n",
      "Epoch 122/170\n",
      " - 0s - loss: 0.2871\n",
      "Epoch 123/170\n",
      " - 0s - loss: 0.2740\n",
      "Epoch 124/170\n",
      " - 0s - loss: 0.3232\n",
      "Epoch 125/170\n",
      " - 0s - loss: 0.2874\n",
      "Epoch 126/170\n",
      " - 0s - loss: 0.2177\n",
      "Epoch 127/170\n",
      " - 0s - loss: 0.2850\n",
      "Epoch 128/170\n",
      " - 0s - loss: 0.2515\n",
      "Epoch 129/170\n",
      " - 0s - loss: 0.2901\n",
      "Epoch 130/170\n",
      " - 0s - loss: 0.3191\n",
      "Epoch 131/170\n",
      " - 0s - loss: 0.2611\n",
      "Epoch 132/170\n",
      " - 0s - loss: 0.3021\n",
      "Epoch 133/170\n",
      " - 0s - loss: 0.3221\n",
      "Epoch 134/170\n",
      " - 0s - loss: 0.2802\n",
      "Epoch 135/170\n",
      " - 0s - loss: 0.2195\n",
      "Epoch 136/170\n",
      " - 0s - loss: 0.2619\n",
      "Epoch 137/170\n",
      " - 0s - loss: 0.2201\n",
      "Epoch 138/170\n",
      " - 0s - loss: 0.1925\n",
      "Epoch 139/170\n",
      " - 0s - loss: 0.2809\n",
      "Epoch 140/170\n",
      " - 0s - loss: 0.2514\n",
      "Epoch 141/170\n",
      " - 0s - loss: 0.2637\n",
      "Epoch 142/170\n",
      " - 0s - loss: 0.1829\n",
      "Epoch 143/170\n",
      " - 0s - loss: 0.2042\n",
      "Epoch 144/170\n",
      " - 0s - loss: 0.2120\n",
      "Epoch 145/170\n",
      " - 0s - loss: 0.2597\n",
      "Epoch 146/170\n",
      " - 0s - loss: 0.2282\n",
      "Epoch 147/170\n",
      " - 0s - loss: 0.2474\n",
      "Epoch 148/170\n",
      " - 0s - loss: 0.2522\n",
      "Epoch 149/170\n",
      " - 0s - loss: 0.2162\n",
      "Epoch 150/170\n",
      " - 0s - loss: 0.3817\n",
      "Epoch 151/170\n",
      " - 0s - loss: 0.1974\n",
      "Epoch 152/170\n",
      " - 0s - loss: 0.1831\n",
      "Epoch 153/170\n",
      " - 0s - loss: 0.2011\n",
      "Epoch 154/170\n",
      " - 0s - loss: 0.1807\n",
      "Epoch 155/170\n",
      " - 0s - loss: 0.1676\n",
      "Epoch 156/170\n",
      " - 0s - loss: 0.1880\n",
      "Epoch 157/170\n",
      " - 0s - loss: 0.1952\n",
      "Epoch 158/170\n",
      " - 0s - loss: 0.2240\n",
      "Epoch 159/170\n",
      " - 0s - loss: 0.2350\n",
      "Epoch 160/170\n",
      " - 0s - loss: 0.1726\n",
      "Epoch 161/170\n",
      " - 0s - loss: 0.1830\n",
      "Epoch 162/170\n",
      " - 0s - loss: 0.2314\n",
      "Epoch 163/170\n",
      " - 0s - loss: 0.1789\n",
      "Epoch 164/170\n",
      " - 0s - loss: 0.2481\n",
      "Epoch 165/170\n",
      " - 0s - loss: 0.1949\n",
      "Epoch 166/170\n",
      " - 0s - loss: 0.1801\n",
      "Epoch 167/170\n",
      " - 0s - loss: 0.2055\n",
      "Epoch 168/170\n",
      " - 0s - loss: 0.2128\n",
      "Epoch 169/170\n",
      " - 0s - loss: 0.1783\n",
      "Epoch 170/170\n",
      " - 0s - loss: 0.2142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x116142ef0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(TrainData2, TrainData1.time, nb_epoch= 170, batch_size=10,  verbose=2)\n",
    "# evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0187730e+00],\n",
       "       [ 8.4220495e+00],\n",
       "       [ 3.0320120e-01],\n",
       "       [ 9.0402800e-01],\n",
       "       [ 1.4948268e+00],\n",
       "       [ 7.0097661e+00],\n",
       "       [ 1.9799732e+00],\n",
       "       [ 4.0537980e-01],\n",
       "       [ 1.1656306e+01],\n",
       "       [ 2.9104206e-01],\n",
       "       [ 2.9299488e+00],\n",
       "       [ 1.2185328e+01],\n",
       "       [ 8.2276875e-01],\n",
       "       [ 2.3821796e+01],\n",
       "       [ 6.4031893e-01],\n",
       "       [ 6.5898889e-01],\n",
       "       [ 8.4845304e-02],\n",
       "       [ 4.2908502e+00],\n",
       "       [ 2.6375515e+00],\n",
       "       [ 1.5685451e-01],\n",
       "       [ 2.4928215e-01],\n",
       "       [ 6.3753510e-01],\n",
       "       [ 4.7139880e-01],\n",
       "       [ 6.8605208e-01],\n",
       "       [ 8.7406033e-01],\n",
       "       [ 1.0065712e+00],\n",
       "       [-1.1421105e+00],\n",
       "       [ 2.0761726e+00],\n",
       "       [ 2.7313352e-01],\n",
       "       [ 1.5483611e+00],\n",
       "       [ 1.9340076e+01],\n",
       "       [ 2.1081567e+00],\n",
       "       [ 4.2988443e-01],\n",
       "       [ 4.4283490e+00],\n",
       "       [ 5.5230556e+00],\n",
       "       [ 8.2356483e-01],\n",
       "       [ 2.9801579e+00],\n",
       "       [ 1.4909644e+00],\n",
       "       [ 7.9981923e-01],\n",
       "       [ 2.1350865e+00],\n",
       "       [ 3.7137713e+00],\n",
       "       [ 7.0681510e+00],\n",
       "       [ 6.9404238e-01],\n",
       "       [ 2.5743155e+00],\n",
       "       [ 5.1636499e-01],\n",
       "       [ 1.7319038e+00],\n",
       "       [ 3.2931807e+00],\n",
       "       [ 5.2795362e-01],\n",
       "       [ 4.9887009e+00],\n",
       "       [ 5.6348729e-01],\n",
       "       [-2.7283505e-03],\n",
       "       [ 2.2055836e+01],\n",
       "       [ 2.4738196e-01],\n",
       "       [ 5.4714227e+00],\n",
       "       [ 9.6879826e+00],\n",
       "       [ 5.7083994e-01],\n",
       "       [ 1.3730511e-01],\n",
       "       [ 8.4101480e-01],\n",
       "       [ 1.1892874e+00],\n",
       "       [-1.2844739e+00],\n",
       "       [ 9.0280789e-01],\n",
       "       [ 4.3653078e+00],\n",
       "       [ 5.9805089e-01],\n",
       "       [ 5.8552237e+00],\n",
       "       [ 3.0522685e+00],\n",
       "       [ 1.0030357e+01],\n",
       "       [ 2.8896782e-01],\n",
       "       [ 4.2483467e-01],\n",
       "       [ 7.7815681e+00],\n",
       "       [ 9.5460910e-01],\n",
       "       [ 4.2097914e-01],\n",
       "       [ 4.9163815e-01],\n",
       "       [ 6.6326418e+00],\n",
       "       [ 2.8721923e-01],\n",
       "       [ 5.5674634e+00],\n",
       "       [ 3.6729772e+00],\n",
       "       [ 7.9358464e-01],\n",
       "       [ 2.3477859e+00],\n",
       "       [ 2.7817445e+00],\n",
       "       [ 8.6236829e-01],\n",
       "       [ 5.6234498e+00],\n",
       "       [ 2.8611200e+00],\n",
       "       [ 3.6683791e+00],\n",
       "       [ 4.1035047e-01],\n",
       "       [ 1.2621851e+00],\n",
       "       [ 2.3270187e+00],\n",
       "       [ 5.0216217e+00],\n",
       "       [ 2.3115295e-01],\n",
       "       [ 2.8269544e+00],\n",
       "       [ 8.5210305e-01],\n",
       "       [ 2.1552124e+00],\n",
       "       [ 5.7391065e-01],\n",
       "       [ 9.0000498e-01],\n",
       "       [ 1.1776688e+01],\n",
       "       [ 5.6110554e+00],\n",
       "       [ 2.4150009e+00],\n",
       "       [ 3.3908123e+01],\n",
       "       [ 5.5449677e-01],\n",
       "       [ 2.1320283e-01],\n",
       "       [ 1.9667456e-01]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1=model.predict(TestData2)\n",
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.018773,\n",
       " 8.4220495,\n",
       " 0.3032012,\n",
       " 0.904028,\n",
       " 1.4948268,\n",
       " 7.009766,\n",
       " 1.9799732,\n",
       " 0.4053798,\n",
       " 11.656306,\n",
       " 0.29104206,\n",
       " 2.9299488,\n",
       " 12.185328,\n",
       " 0.82276875,\n",
       " 23.821796,\n",
       " 0.64031893,\n",
       " 0.6589889,\n",
       " 0.084845304,\n",
       " 4.29085,\n",
       " 2.6375515,\n",
       " 0.15685451,\n",
       " 0.24928215,\n",
       " 0.6375351,\n",
       " 0.4713988,\n",
       " 0.6860521,\n",
       " 0.87406033,\n",
       " 1.0065712,\n",
       " -1.1421105,\n",
       " 2.0761726,\n",
       " 0.27313352,\n",
       " 1.5483611,\n",
       " 19.340076,\n",
       " 2.1081567,\n",
       " 0.42988443,\n",
       " 4.428349,\n",
       " 5.5230556,\n",
       " 0.8235648,\n",
       " 2.9801579,\n",
       " 1.4909644,\n",
       " 0.79981923,\n",
       " 2.1350865,\n",
       " 3.7137713,\n",
       " 7.068151,\n",
       " 0.6940424,\n",
       " 2.5743155,\n",
       " 0.516365,\n",
       " 1.7319038,\n",
       " 3.2931807,\n",
       " 0.5279536,\n",
       " 4.988701,\n",
       " 0.5634873,\n",
       " -0.0027283505,\n",
       " 22.055836,\n",
       " 0.24738196,\n",
       " 5.4714227,\n",
       " 9.687983,\n",
       " 0.57083994,\n",
       " 0.13730511,\n",
       " 0.8410148,\n",
       " 1.1892874,\n",
       " -1.2844739,\n",
       " 0.9028079,\n",
       " 4.365308,\n",
       " 0.5980509,\n",
       " 5.8552237,\n",
       " 3.0522685,\n",
       " 10.030357,\n",
       " 0.28896782,\n",
       " 0.42483467,\n",
       " 7.781568,\n",
       " 0.9546091,\n",
       " 0.42097914,\n",
       " 0.49163815,\n",
       " 6.632642,\n",
       " 0.28721923,\n",
       " 5.5674634,\n",
       " 3.6729772,\n",
       " 0.79358464,\n",
       " 2.347786,\n",
       " 2.7817445,\n",
       " 0.8623683,\n",
       " 5.62345,\n",
       " 2.86112,\n",
       " 3.668379,\n",
       " 0.41035047,\n",
       " 1.2621851,\n",
       " 2.3270187,\n",
       " 5.0216217,\n",
       " 0.23115295,\n",
       " 2.8269544,\n",
       " 0.85210305,\n",
       " 2.1552124,\n",
       " 0.57391065,\n",
       " 0.900005,\n",
       " 11.776688,\n",
       " 5.6110554,\n",
       " 2.415001,\n",
       " 33.908123,\n",
       " 0.55449677,\n",
       " 0.21320283,\n",
       " 0.19667456]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2=[]\n",
    "for i in range(0,100):\n",
    "    y2.append(y1[i][0])\n",
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    if y2[i]<0:\n",
    "        y2[i] = TestData2['time_pre'][i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"id\":TestData['id'],\"time\":list(y2)}).to_csv('/Users/wyx/Desktop/5001prediction.csv', columns=['id','time'],index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
