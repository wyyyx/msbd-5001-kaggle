{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "TrainData = pd.read_csv(\"5001train.csv\")\n",
    "TestData  = pd.read_csv(\"5001test.csv\")\n",
    "from pandas.core.frame import DataFrame\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# supposed maximal n_jobs is 16\n",
    "for i in range(400):\n",
    "    if TrainData['n_jobs'][i] == -1:\n",
    "        TrainData['n_jobs'][i] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399 [0.5287737846374512, 3.108427047729492, 0.3647949695587158, 1.022508144378662, 0.716839075088501, 12.551417112350464, 2.380812168121338, 5.002321004867554, 0.8260650634765625, 3.179537296295166, 2.6557888984680176, 1.1288769245147705, 0.8204910755157471, 3.0569889545440674, 1.7499809265136719, 0.10687422752380371, 1.5837430953979492, 0.41169190406799316, 1.44844388961792, 4.019684076309204, 0.10852193832397461, 0.4156479835510254, 0.6117250919342041, 0.6210618019104004, 2.3756959438323975, 0.5251290798187256, 2.159442186355591, 0.4118032455444336, 1.2265751361846924, 2.869878053665161, 1.6649539470672607, 0.5180611610412598, 0.20778799057006836, 5.014949798583984, 0.7200651168823242, 1.962796926498413, 5.246016979217529, 0.20919394493103027, 19.081645965576172, 0.10424518585205078, 11.385681867599487, 3.3038699626922607, 0.718425989151001, 0.4190359115600586, 0.6203067302703857, 2.5779459476470947, 5.815141916275024, 15.309467792510986, 19.17103624343872, 0.10719680786132812, 5.00507116317749, 1.8415708541870117, 5.388819217681885, 0.7342128753662109, 0.5086240768432617, 9.475033044815063, 2.567985773086548, 0.41889286041259766, 4.5985729694366455, 0.827023983001709, 2.6573989391326904, 0.954636812210083, 2.159210205078125, 1.129885196685791, 2.372515916824341, 0.7112457752227783, 3.7353639602661133, 0.4122428894042969, 1.6252388954162598, 0.416837215423584, 2.146394968032837, 0.4704749584197998, 11.761623859405518, 0.8776919841766357, 0.30509495735168457, 8.615908861160278, 12.877722978591919, 2.2035341262817383, 2.6750540733337402, 1.3669440746307373, 0.817755937576294, 10.2119779586792, 3.555359363555908, 1.5365447998046875, 9.573163032531738, 0.20435190200805664, 1.4710490703582764, 0.3158578872680664, 3.065490961074829, 0.8178892135620117, 1.4447178840637207, 1.4396169185638428, 1.9482769966125488, 0.6165080070495605, 1.3297488689422607, 0.6176338195800781, 4.706434011459351, 8.302245140075684, 0.21509289741516113, 1.7418642044067383, 1.6520798206329346, 2.986415147781372, 3.1944079399108887, 5.3138251304626465, 1.3351352214813232, 1.4419503211975098, 0.7198970317840576, 0.6438450813293457, 4.3796257972717285, 1.0214860439300537, 1.025376796722412, 0.0809779167175293, 0.13602995872497559, 1.032135248184204, 2.0716569423675537, 9.87890076637268, 4.000591039657593, 2.7595362663269043, 7.036646127700806, 14.604634046554565, 1.7414839267730713, 0.7126550674438477, 1.4421629905700684, 2.1590750217437744, 0.5096280574798584, 5.222800970077515, 15.920392990112305, 0.8229660987854004, 0.32737016677856445, 8.031869888305664, 2.2402501106262207, 2.248049259185791, 0.7174530029296875, 7.361464023590088, 3.2976667881011963, 0.12568306922912598, 3.5763561725616455, 8.04139518737793, 4.6076648235321045, 0.6966331005096436, 4.424465179443359, 14.82671594619751, 5.488461971282959, 1.4312798976898193, 0.6605172157287598, 0.51416015625, 12.894047975540161, 6.36352801322937, 0.4164550304412842, 1.0421020984649658, 0.3279411792755127, 0.5208020210266113, 2.1685738563537598, 1.036902904510498, 0.3159627914428711, 2.0618529319763184, 13.949808120727539, 1.3354160785675049, 1.8424901962280273, 0.12389111518859863, 0.12444210052490234, 2.069843053817749, 6.5232250690460205, 0.10428786277770996, 1.8548040390014648, 14.349869012832642, 4.339169025421143, 0.5142171382904053, 11.868890762329102, 4.827401876449585, 1.408696174621582, 4.910968780517578, 2.5086758136749268, 13.690213918685913, 5.316067695617676, 0.41053104400634766, 2.6623270511627197, 9.872227191925049, 21.500651121139526, 6.650718927383423, 2.067293882369995, 1.1401262283325195, 0.8254349231719971, 5.297055959701538, 5.711073160171509, 9.502803087234497, 9.181822776794434, 3.2727057933807373, 2.455394983291626, 1.4373340606689453, 0.4127051830291748, 0.9210929870605469, 2.0418319702148438, 1.3330790996551514, 3.870767116546631, 2.139227867126465, 3.059083938598633, 0.7742190361022949, 2.6891238689422607, 2.596349000930786, 2.985422134399414, 0.31214475631713867, 3.516152858734131, 1.231017827987671, 2.2468998432159424, 2.3421037197113037, 1.3591980934143066, 1.5336151123046875, 1.3337578773498535, 0.18099284172058105, 1.0214447975158691, 0.6315121650695801, 2.1524951457977295, 2.245651960372925, 36.82856607437134, 15.510921955108643, 1.0305747985839844, 7.047455549240112, 0.31667590141296387, 0.6750738620758057, 2.3760130405426025, 2.2800161838531494, 9.927421808242798, 3.6991829872131348, 19.93153977394104, 1.5579063892364502, 1.179412841796875, 1.2822511196136475, 3.9487318992614746, 0.7302792072296143, 0.5213570594787598, 5.94364595413208, 5.653739929199219, 17.408305883407593, 0.10616087913513184, 5.672400951385498, 0.20756316184997559, 0.4895312786102295, 10.465802907943726, 1.8285212516784668, 4.3022520542144775, 11.741996049880981, 6.526199102401733, 3.2674338817596436, 3.775315761566162, 1.2227509021759033, 3.9019429683685303, 0.41232895851135254, 1.6346700191497803, 2.153658866882324, 6.009807109832764, 1.2283480167388916, 4.893051862716675, 14.422080039978027, 1.7355022430419922, 6.1419878005981445, 0.5097520351409912, 4.120248079299927, 1.3346049785614014, 3.831860065460205, 7.733136892318726, 1.8557970523834229, 0.31178975105285645, 0.5005607604980469, 1.135085105895996, 0.925347089767456, 1.6470201015472412, 1.2428309917449951, 0.6469020843505859, 1.3097951412200928, 3.8121490478515625, 0.11278223991394043, 1.3541018962860107, 9.03854489326477, 7.551203966140747, 1.9744081497192383, 1.3454678058624268, 0.3170158863067627, 1.6614341735839844, 2.8109166622161865, 2.5708351135253906, 1.0699238777160645, 0.6166501045227051, 1.047494888305664, 6.396213054656982, 4.828541040420532, 0.2683711051940918, 3.167243003845215, 14.3997061252594, 5.261759996414185, 1.4261538982391357, 1.3182392120361328, 7.980163097381592, 0.615811824798584, 3.264382839202881, 1.6355979442596436, 0.41790080070495605, 3.8750181198120117, 11.553821086883545, 0.3140449523925781, 24.57223391532898, 3.422435998916626, 1.9529969692230225, 2.6479880809783936, 0.9741051197052002, 1.0936822891235352, 15.562372207641602, 1.4355058670043945, 0.5180830955505371, 13.05526089668274, 0.24338006973266602, 0.9221570491790771, 0.617988109588623, 0.16934800148010254, 0.4866461753845215, 0.40978288650512695, 3.9722681045532227, 4.713926315307617, 0.418626070022583, 6.5072832107543945, 30.76228404045105, 1.6323328018188477, 7.682777166366577, 0.4112668037414551, 0.8704860210418701, 0.13311195373535156, 16.13510012626648, 0.204240083694458, 0.10599493980407715, 0.19428682327270508, 0.5145440101623535, 0.40667271614074707, 0.10724401473999023, 1.2486259937286377, 0.10421609878540039, 2.9610602855682373, 38.380277156829834, 0.31032586097717285, 0.5930180549621582, 4.541189908981323, 5.416004180908203, 3.688526153564453, 0.4315299987792969, 0.2048499584197998, 0.7740991115570068, 1.1618578433990479, 9.008701086044312, 21.102274179458618, 0.5115048885345459, 2.3389854431152344, 13.521346092224121, 10.501068115234375, 1.320350170135498, 1.057945728302002, 4.000926971435547, 3.1598689556121826, 5.837935924530029, 4.963228940963745, 1.675260305404663, 3.8172101974487305, 0.6353790760040283, 4.103880882263184, 0.29339599609375, 3.6535580158233643, 1.1227059364318848, 0.5163500308990479, 1.2217209339141846, 0.21878719329833984, 0.519719123840332, 1.2396180629730225, 0.2091069221496582, 4.980291843414307, 2.779540777206421, 7.536048889160156, 4.067412853240967, 6.223984956741333, 16.65813684463501, 5.079465866088867, 0.2081890106201172, 0.9445061683654785, 0.43259429931640625, 21.342159748077393, 0.8225290775299072, 0.8321709632873535, 2.8498401641845703, 0.4657630920410156, 6.516363859176636, 0.5179357528686523, 3.4649930000305176, 5.615211009979248, 0.20357823371887207, 9.808586120605469, 0.10647797584533691, 4.172821998596191, 1.6479690074920654, 1.3367772102355957, 4.678377866744995, 2.285008192062378, 2.1850461959838867, 0.28858304023742676]\n"
     ]
    }
   ],
   "source": [
    "#print real time\n",
    "result=[]\n",
    "for i in  range(0, 400):\n",
    "    X1,Y1=make_classification(n_samples = TrainData.iat[i,7], n_features= TrainData.iat[i,8] , n_classes = TrainData.iat[i,9]  , n_clusters_per_class = TrainData.iat[i,10] ,n_informative = TrainData.iat[i,11], flip_y= TrainData.iat[i,12] , scale= TrainData.iat[i,13])\n",
    "    import time\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    clf = SGDClassifier(penalty = TrainData.iat[i,1], l1_ratio = TrainData.iat[i,2], alpha = TrainData.iat[i,3], max_iter = TrainData.iat[i,4], random_state = TrainData.iat[i,5], n_jobs = TrainData.iat[i,6])\n",
    "    start = time.time()  \n",
    "    clf.fit(X1, Y1)\n",
    "    elapsed = (time.time() - start)\n",
    "    result.append(elapsed)  \n",
    "print(i,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "TrainData['time_pre']=result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData1 = pd.get_dummies(TrainData, columns = ['penalty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "f=pd.DataFrame({\"id\":TrainData['id'], \"time\":TrainData['time'],\"time_pred\":TrainData1['time_pre']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData2 = TrainData1[['l1_ratio' , 'alpha' , 'max_iter' , 'n_jobs' , 'n_samples' , 'n_features' , 'n_classes' , 'n_clusters_per_class'  , 'flip_y' , 'scale', 'time_pre', 'penalty_elasticnet', 'penalty_l1','penalty_l2','penalty_none']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3694: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "n_samplefeature = TrainData2.n_samples*TrainData2.n_features\n",
    "TrainData2['nsamplefeature'] =n_samplefeature\n",
    "TrainData2.drop('n_samples',axis=1, inplace=True)\n",
    "TrainData2.drop('n_features',axis=1, inplace=True)\n",
    "n_classes1 = TrainData2.n_classes*TrainData2.n_clusters_per_class\n",
    "TrainData2['n_classes1'] =n_classes1\n",
    "TrainData2.drop('n_classes',axis=1, inplace=True)\n",
    "TrainData2.drop('n_clusters_per_class',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData2=TrainData2.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=13, activation=\"relu\", units=1000, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1000, units=1, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(output_dim=1000, input_dim=13, init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(output_dim=1, input_dim=1000,init='uniform'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    if TestData['n_jobs'][i] == -1:\n",
    "        TestData['n_jobs'][i] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 [1.8439350128173828, 15.163701057434082, 0.9275729656219482, 2.476964235305786, 3.417428970336914, 13.073661804199219, 2.782838821411133, 1.0379631519317627, 12.739984035491943, 0.49919795989990234, 5.460515975952148, 42.91088795661926, 1.1511502265930176, 23.30795693397522, 0.15194082260131836, 0.7323782444000244, 1.0313589572906494, 9.477136135101318, 2.778496026992798, 2.071234941482544, 0.3114309310913086, 0.3738260269165039, 0.7225978374481201, 0.822598934173584, 2.047658920288086, 3.295024871826172, 1.657109022140503, 9.006521224975586, 1.4531900882720947, 2.6983988285064697, 18.56486225128174, 2.9110682010650635, 1.348106861114502, 6.547025918960571, 16.632874011993408, 1.1218318939208984, 5.332128047943115, 4.603480100631714, 1.3356549739837646, 2.2984557151794434, 9.739620685577393, 8.502506017684937, 1.4415867328643799, 14.61195993423462, 1.2290401458740234, 1.5208640098571777, 5.639392137527466, 1.3312718868255615, 9.06163477897644, 1.9462080001831055, 0.321505069732666, 35.94034814834595, 0.20817899703979492, 11.545248985290527, 15.8230881690979, 0.3615708351135254, 2.146862745285034, 2.767315149307251, 0.7851979732513428, 1.632694959640503, 1.5371499061584473, 7.0361762046813965, 0.8644506931304932, 25.48219609260559, 4.2877771854400635, 43.98281002044678, 1.0205600261688232, 1.1273510456085205, 13.343456745147705, 1.6444177627563477, 0.514214038848877, 1.0223841667175293, 9.06658387184143, 0.3621339797973633, 10.818181991577148, 5.711242914199829, 2.565432071685791, 5.303907155990601, 6.753381967544556, 1.4557859897613525, 20.973562002182007, 6.451974868774414, 8.1942880153656, 1.8331866264343262, 1.1224017143249512, 5.3207409381866455, 13.93629503250122, 0.5308873653411865, 4.258373975753784, 1.1439309120178223, 3.6245789527893066, 1.2006959915161133, 2.0579540729522705, 25.60652208328247, 8.702075719833374, 4.688421964645386, 39.07152271270752, 0.5103850364685059, 0.9161510467529297, 0.11409807205200195]\n"
     ]
    }
   ],
   "source": [
    "result2=[]\n",
    "for i in  range(0, 100):\n",
    "    X2,Y2=make_classification(n_samples = TestData.iat[i,7], n_features= TestData.iat[i,8] , n_classes = TestData.iat[i,9]  , n_clusters_per_class = TestData.iat[i,10] ,n_informative = TestData.iat[i,11], flip_y= TestData.iat[i,12] , scale= TestData.iat[i,13])\n",
    "    import time\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    clf = SGDClassifier(penalty = TestData.iat[i,1], l1_ratio = TestData.iat[i,2], alpha = TestData.iat[i,3], max_iter = TestData.iat[i,4], random_state = TestData.iat[i,5], n_jobs = TestData.iat[i,6])\n",
    "    start = time.time()  \n",
    "    clf.fit(X2, Y2)\n",
    "    elapsed = (time.time() - start)\n",
    "    result2.append(elapsed)  \n",
    "print(i,result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "TestData['time_pre']=result2\n",
    "TestData1 = pd.get_dummies(TestData, columns = ['penalty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestData2 = TestData1[['l1_ratio' , 'alpha' , 'max_iter'  , 'n_jobs' , 'n_samples' , 'n_features' , 'n_classes' , 'n_clusters_per_class' , 'flip_y' , 'scale', 'time_pre', 'penalty_elasticnet', 'penalty_l1','penalty_l2','penalty_none']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3694: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "n_samplefeature = TestData2.n_samples*TestData2.n_features\n",
    "TestData2['nsamplefeature'] =n_samplefeature\n",
    "TestData2.drop('n_samples',axis=1, inplace=True)\n",
    "TestData2.drop('n_features',axis=1, inplace=True)\n",
    "TestData2['n_classes1'] =n_classes1\n",
    "TestData2.drop('n_classes',axis=1, inplace=True)\n",
    "TestData2.drop('n_clusters_per_class',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestData2=TestData2.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/170\n",
      " - 1s - loss: 30.6006\n",
      "Epoch 2/170\n",
      " - 0s - loss: 21.8562\n",
      "Epoch 3/170\n",
      " - 0s - loss: 17.6311\n",
      "Epoch 4/170\n",
      " - 0s - loss: 14.6310\n",
      "Epoch 5/170\n",
      " - 0s - loss: 12.1326\n",
      "Epoch 6/170\n",
      " - 0s - loss: 10.1143\n",
      "Epoch 7/170\n",
      " - 0s - loss: 8.7777\n",
      "Epoch 8/170\n",
      " - 0s - loss: 7.4324\n",
      "Epoch 9/170\n",
      " - 0s - loss: 6.1283\n",
      "Epoch 10/170\n",
      " - 0s - loss: 5.4824\n",
      "Epoch 11/170\n",
      " - 0s - loss: 4.7884\n",
      "Epoch 12/170\n",
      " - 0s - loss: 4.3566\n",
      "Epoch 13/170\n",
      " - 0s - loss: 3.6856\n",
      "Epoch 14/170\n",
      " - 0s - loss: 3.4334\n",
      "Epoch 15/170\n",
      " - 0s - loss: 2.9705\n",
      "Epoch 16/170\n",
      " - 0s - loss: 2.9012\n",
      "Epoch 17/170\n",
      " - 0s - loss: 2.4204\n",
      "Epoch 18/170\n",
      " - 0s - loss: 2.4432\n",
      "Epoch 19/170\n",
      " - 0s - loss: 1.9434\n",
      "Epoch 20/170\n",
      " - 0s - loss: 1.8175\n",
      "Epoch 21/170\n",
      " - 0s - loss: 1.8308\n",
      "Epoch 22/170\n",
      " - 0s - loss: 1.5964\n",
      "Epoch 23/170\n",
      " - 0s - loss: 1.6265\n",
      "Epoch 24/170\n",
      " - 0s - loss: 1.4979\n",
      "Epoch 25/170\n",
      " - 0s - loss: 1.3656\n",
      "Epoch 26/170\n",
      " - 0s - loss: 1.2759\n",
      "Epoch 27/170\n",
      " - 0s - loss: 1.2626\n",
      "Epoch 28/170\n",
      " - 0s - loss: 1.2285\n",
      "Epoch 29/170\n",
      " - 0s - loss: 1.1659\n",
      "Epoch 30/170\n",
      " - 0s - loss: 1.2720\n",
      "Epoch 31/170\n",
      " - 0s - loss: 1.1049\n",
      "Epoch 32/170\n",
      " - 0s - loss: 1.2887\n",
      "Epoch 33/170\n",
      " - 0s - loss: 1.2534\n",
      "Epoch 34/170\n",
      " - 0s - loss: 1.1416\n",
      "Epoch 35/170\n",
      " - 0s - loss: 1.0588\n",
      "Epoch 36/170\n",
      " - 0s - loss: 0.9431\n",
      "Epoch 37/170\n",
      " - 0s - loss: 0.9433\n",
      "Epoch 38/170\n",
      " - 0s - loss: 0.8277\n",
      "Epoch 39/170\n",
      " - 0s - loss: 0.9649\n",
      "Epoch 40/170\n",
      " - 0s - loss: 0.9057\n",
      "Epoch 41/170\n",
      " - 0s - loss: 0.9648\n",
      "Epoch 42/170\n",
      " - 0s - loss: 0.8464\n",
      "Epoch 43/170\n",
      " - 0s - loss: 0.7809\n",
      "Epoch 44/170\n",
      " - 0s - loss: 0.7929\n",
      "Epoch 45/170\n",
      " - 0s - loss: 0.8008\n",
      "Epoch 46/170\n",
      " - 0s - loss: 0.8152\n",
      "Epoch 47/170\n",
      " - 0s - loss: 0.8109\n",
      "Epoch 48/170\n",
      " - 0s - loss: 0.9148\n",
      "Epoch 49/170\n",
      " - 0s - loss: 0.7309\n",
      "Epoch 50/170\n",
      " - 0s - loss: 0.8853\n",
      "Epoch 51/170\n",
      " - 0s - loss: 0.8012\n",
      "Epoch 52/170\n",
      " - 0s - loss: 0.8435\n",
      "Epoch 53/170\n",
      " - 0s - loss: 0.7787\n",
      "Epoch 54/170\n",
      " - 0s - loss: 0.7242\n",
      "Epoch 55/170\n",
      " - 0s - loss: 0.7247\n",
      "Epoch 56/170\n",
      " - 0s - loss: 0.9164\n",
      "Epoch 57/170\n",
      " - 0s - loss: 0.7155\n",
      "Epoch 58/170\n",
      " - 0s - loss: 0.6683\n",
      "Epoch 59/170\n",
      " - 0s - loss: 0.7583\n",
      "Epoch 60/170\n",
      " - 0s - loss: 0.8414\n",
      "Epoch 61/170\n",
      " - 0s - loss: 0.7705\n",
      "Epoch 62/170\n",
      " - 0s - loss: 0.6203\n",
      "Epoch 63/170\n",
      " - 0s - loss: 0.8049\n",
      "Epoch 64/170\n",
      " - 0s - loss: 0.6398\n",
      "Epoch 65/170\n",
      " - 0s - loss: 0.6901\n",
      "Epoch 66/170\n",
      " - 0s - loss: 0.6275\n",
      "Epoch 67/170\n",
      " - 0s - loss: 0.5500\n",
      "Epoch 68/170\n",
      " - 0s - loss: 0.6986\n",
      "Epoch 69/170\n",
      " - 0s - loss: 0.5540\n",
      "Epoch 70/170\n",
      " - 0s - loss: 0.6780\n",
      "Epoch 71/170\n",
      " - 0s - loss: 0.6766\n",
      "Epoch 72/170\n",
      " - 0s - loss: 0.6190\n",
      "Epoch 73/170\n",
      " - 0s - loss: 0.5602\n",
      "Epoch 74/170\n",
      " - 0s - loss: 0.6410\n",
      "Epoch 75/170\n",
      " - 0s - loss: 0.6255\n",
      "Epoch 76/170\n",
      " - 0s - loss: 0.5781\n",
      "Epoch 77/170\n",
      " - 0s - loss: 0.6176\n",
      "Epoch 78/170\n",
      " - 0s - loss: 0.5908\n",
      "Epoch 79/170\n",
      " - 0s - loss: 0.5989\n",
      "Epoch 80/170\n",
      " - 0s - loss: 0.5423\n",
      "Epoch 81/170\n",
      " - 0s - loss: 0.6099\n",
      "Epoch 82/170\n",
      " - 0s - loss: 0.5601\n",
      "Epoch 83/170\n",
      " - 0s - loss: 0.5707\n",
      "Epoch 84/170\n",
      " - 0s - loss: 0.6108\n",
      "Epoch 85/170\n",
      " - 0s - loss: 0.5399\n",
      "Epoch 86/170\n",
      " - 0s - loss: 0.5223\n",
      "Epoch 87/170\n",
      " - 0s - loss: 0.5382\n",
      "Epoch 88/170\n",
      " - 0s - loss: 0.5297\n",
      "Epoch 89/170\n",
      " - 0s - loss: 0.5339\n",
      "Epoch 90/170\n",
      " - 0s - loss: 0.4419\n",
      "Epoch 91/170\n",
      " - 0s - loss: 0.5035\n",
      "Epoch 92/170\n",
      " - 0s - loss: 0.4250\n",
      "Epoch 93/170\n",
      " - 0s - loss: 0.5177\n",
      "Epoch 94/170\n",
      " - 0s - loss: 0.5254\n",
      "Epoch 95/170\n",
      " - 0s - loss: 0.5398\n",
      "Epoch 96/170\n",
      " - 0s - loss: 0.5595\n",
      "Epoch 97/170\n",
      " - 0s - loss: 0.5234\n",
      "Epoch 98/170\n",
      " - 0s - loss: 0.5344\n",
      "Epoch 99/170\n",
      " - 0s - loss: 0.5325\n",
      "Epoch 100/170\n",
      " - 0s - loss: 0.4362\n",
      "Epoch 101/170\n",
      " - 0s - loss: 0.5137\n",
      "Epoch 102/170\n",
      " - 0s - loss: 0.5813\n",
      "Epoch 103/170\n",
      " - 0s - loss: 0.4497\n",
      "Epoch 104/170\n",
      " - 0s - loss: 0.5195\n",
      "Epoch 105/170\n",
      " - 0s - loss: 0.5211\n",
      "Epoch 106/170\n",
      " - 0s - loss: 0.5296\n",
      "Epoch 107/170\n",
      " - 0s - loss: 0.4969\n",
      "Epoch 108/170\n",
      " - 0s - loss: 0.4570\n",
      "Epoch 109/170\n",
      " - 0s - loss: 0.5222\n",
      "Epoch 110/170\n",
      " - 0s - loss: 0.4222\n",
      "Epoch 111/170\n",
      " - 0s - loss: 0.4453\n",
      "Epoch 112/170\n",
      " - 0s - loss: 0.4098\n",
      "Epoch 113/170\n",
      " - 0s - loss: 0.3694\n",
      "Epoch 114/170\n",
      " - 0s - loss: 0.4021\n",
      "Epoch 115/170\n",
      " - 0s - loss: 0.4427\n",
      "Epoch 116/170\n",
      " - 0s - loss: 0.3967\n",
      "Epoch 117/170\n",
      " - 0s - loss: 0.4213\n",
      "Epoch 118/170\n",
      " - 0s - loss: 0.4715\n",
      "Epoch 119/170\n",
      " - 0s - loss: 0.4385\n",
      "Epoch 120/170\n",
      " - 0s - loss: 0.4239\n",
      "Epoch 121/170\n",
      " - 0s - loss: 0.3986\n",
      "Epoch 122/170\n",
      " - 0s - loss: 0.4098\n",
      "Epoch 123/170\n",
      " - 0s - loss: 0.4054\n",
      "Epoch 124/170\n",
      " - 0s - loss: 0.3790\n",
      "Epoch 125/170\n",
      " - 0s - loss: 0.4075\n",
      "Epoch 126/170\n",
      " - 0s - loss: 0.4422\n",
      "Epoch 127/170\n",
      " - 0s - loss: 0.3648\n",
      "Epoch 128/170\n",
      " - 0s - loss: 0.3864\n",
      "Epoch 129/170\n",
      " - 0s - loss: 0.3259\n",
      "Epoch 130/170\n",
      " - 0s - loss: 0.3730\n",
      "Epoch 131/170\n",
      " - 0s - loss: 0.3930\n",
      "Epoch 132/170\n",
      " - 0s - loss: 0.3313\n",
      "Epoch 133/170\n",
      " - 0s - loss: 0.3502\n",
      "Epoch 134/170\n",
      " - 0s - loss: 0.3549\n",
      "Epoch 135/170\n",
      " - 0s - loss: 0.3749\n",
      "Epoch 136/170\n",
      " - 0s - loss: 0.3238\n",
      "Epoch 137/170\n",
      " - 0s - loss: 0.3578\n",
      "Epoch 138/170\n",
      " - 0s - loss: 0.3925\n",
      "Epoch 139/170\n",
      " - 0s - loss: 0.3116\n",
      "Epoch 140/170\n",
      " - 0s - loss: 0.3372\n",
      "Epoch 141/170\n",
      " - 0s - loss: 0.3441\n",
      "Epoch 142/170\n",
      " - 0s - loss: 0.4647\n",
      "Epoch 143/170\n",
      " - 0s - loss: 0.3862\n",
      "Epoch 144/170\n",
      " - 0s - loss: 0.2973\n",
      "Epoch 145/170\n",
      " - 0s - loss: 0.2950\n",
      "Epoch 146/170\n",
      " - 0s - loss: 0.3801\n",
      "Epoch 147/170\n",
      " - 0s - loss: 0.3595\n",
      "Epoch 148/170\n",
      " - 0s - loss: 0.3380\n",
      "Epoch 149/170\n",
      " - 0s - loss: 0.2620\n",
      "Epoch 150/170\n",
      " - 0s - loss: 0.3326\n",
      "Epoch 151/170\n",
      " - 0s - loss: 0.3412\n",
      "Epoch 152/170\n",
      " - 0s - loss: 0.3338\n",
      "Epoch 153/170\n",
      " - 0s - loss: 0.3245\n",
      "Epoch 154/170\n",
      " - 0s - loss: 0.3202\n",
      "Epoch 155/170\n",
      " - 0s - loss: 0.3087\n",
      "Epoch 156/170\n",
      " - 0s - loss: 0.3173\n",
      "Epoch 157/170\n",
      " - 0s - loss: 0.3850\n",
      "Epoch 158/170\n",
      " - 0s - loss: 0.2528\n",
      "Epoch 159/170\n",
      " - 0s - loss: 0.3364\n",
      "Epoch 160/170\n",
      " - 0s - loss: 0.2933\n",
      "Epoch 161/170\n",
      " - 0s - loss: 0.3082\n",
      "Epoch 162/170\n",
      " - 0s - loss: 0.3119\n",
      "Epoch 163/170\n",
      " - 0s - loss: 0.3596\n",
      "Epoch 164/170\n",
      " - 0s - loss: 0.2935\n",
      "Epoch 165/170\n",
      " - 0s - loss: 0.2356\n",
      "Epoch 166/170\n",
      " - 0s - loss: 0.3489\n",
      "Epoch 167/170\n",
      " - 0s - loss: 0.3156\n",
      "Epoch 168/170\n",
      " - 0s - loss: 0.2893\n",
      "Epoch 169/170\n",
      " - 0s - loss: 0.2331\n",
      "Epoch 170/170\n",
      " - 0s - loss: 0.2925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2ef31240>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(TrainData2, TrainData1.time, nb_epoch= 170, batch_size=10,  verbose=2)\n",
    "# evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.01831365e+00],\n",
       "       [ 8.93522930e+00],\n",
       "       [ 2.52116859e-01],\n",
       "       [ 7.50527442e-01],\n",
       "       [ 1.44519663e+00],\n",
       "       [ 8.07172871e+00],\n",
       "       [ 1.43982124e+00],\n",
       "       [ 3.30507785e-01],\n",
       "       [ 1.26811934e+01],\n",
       "       [ 3.15798879e-01],\n",
       "       [ 3.80253482e+00],\n",
       "       [ 1.20189781e+01],\n",
       "       [ 5.31290889e-01],\n",
       "       [ 2.44364128e+01],\n",
       "       [ 1.22383222e-01],\n",
       "       [ 1.66564018e-01],\n",
       "       [ 1.19008034e-01],\n",
       "       [ 4.44333410e+00],\n",
       "       [ 1.59211445e+00],\n",
       "       [ 8.88595641e-01],\n",
       "       [ 1.52544022e-01],\n",
       "       [ 3.03361595e-01],\n",
       "       [ 2.77114153e-01],\n",
       "       [-1.13095090e-01],\n",
       "       [ 6.22438610e-01],\n",
       "       [ 1.10185862e+00],\n",
       "       [ 1.67654648e-01],\n",
       "       [ 2.16837668e+00],\n",
       "       [ 1.07822692e+00],\n",
       "       [ 2.64055705e+00],\n",
       "       [ 2.08564644e+01],\n",
       "       [ 1.06620717e+00],\n",
       "       [ 2.91284442e-01],\n",
       "       [ 4.60457325e+00],\n",
       "       [ 5.65910578e+00],\n",
       "       [ 4.97331589e-01],\n",
       "       [ 3.79556727e+00],\n",
       "       [ 2.03920722e+00],\n",
       "       [ 4.63647574e-01],\n",
       "       [ 1.25393605e+00],\n",
       "       [ 3.58803153e+00],\n",
       "       [ 6.44110441e+00],\n",
       "       [ 3.27966273e-01],\n",
       "       [ 2.64143801e+00],\n",
       "       [ 6.00651026e-01],\n",
       "       [ 2.85516477e+00],\n",
       "       [ 3.21754694e+00],\n",
       "       [ 2.71973073e-01],\n",
       "       [ 4.92110872e+00],\n",
       "       [ 5.13179064e-01],\n",
       "       [-3.93308997e-02],\n",
       "       [ 2.46056633e+01],\n",
       "       [-6.89797848e-02],\n",
       "       [ 6.11261177e+00],\n",
       "       [ 9.05400944e+00],\n",
       "       [ 2.05253303e-01],\n",
       "       [ 2.66781747e-02],\n",
       "       [ 7.60055840e-01],\n",
       "       [ 6.15164280e-01],\n",
       "       [ 1.17213321e+00],\n",
       "       [ 1.01319337e+00],\n",
       "       [ 3.99374819e+00],\n",
       "       [ 3.43066007e-01],\n",
       "       [ 6.40409756e+00],\n",
       "       [ 2.98580647e+00],\n",
       "       [ 7.73671436e+00],\n",
       "       [ 4.53735828e-01],\n",
       "       [ 7.99945295e-02],\n",
       "       [ 1.04315176e+01],\n",
       "       [ 6.28685415e-01],\n",
       "       [ 2.90614128e-01],\n",
       "       [ 4.67410684e-01],\n",
       "       [ 6.88351536e+00],\n",
       "       [ 1.50562495e-01],\n",
       "       [ 5.49117565e+00],\n",
       "       [ 6.38005829e+00],\n",
       "       [ 8.17769468e-01],\n",
       "       [ 2.03052545e+00],\n",
       "       [ 3.04907203e+00],\n",
       "       [ 7.85462320e-01],\n",
       "       [ 5.71986580e+00],\n",
       "       [ 3.17905402e+00],\n",
       "       [ 3.31358314e+00],\n",
       "       [ 4.26471710e-01],\n",
       "       [ 1.36960745e+00],\n",
       "       [ 1.79292321e+00],\n",
       "       [ 5.13073301e+00],\n",
       "       [-3.24079990e-02],\n",
       "       [ 2.18511033e+00],\n",
       "       [ 3.25765014e-01],\n",
       "       [ 2.65201116e+00],\n",
       "       [ 4.81251568e-01],\n",
       "       [ 5.61907172e-01],\n",
       "       [ 1.46665087e+01],\n",
       "       [ 6.59679842e+00],\n",
       "       [ 2.70472550e+00],\n",
       "       [ 3.31650124e+01],\n",
       "       [ 2.20870033e-01],\n",
       "       [ 1.40110731e-01],\n",
       "       [-1.72383785e-01]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1=model.predict(TestData2)\n",
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0183136,\n",
       " 8.935229,\n",
       " 0.25211686,\n",
       " 0.75052744,\n",
       " 1.4451966,\n",
       " 8.071729,\n",
       " 1.4398212,\n",
       " 0.33050779,\n",
       " 12.681193,\n",
       " 0.31579888,\n",
       " 3.8025348,\n",
       " 12.018978,\n",
       " 0.5312909,\n",
       " 24.436413,\n",
       " 0.12238322,\n",
       " 0.16656402,\n",
       " 0.119008034,\n",
       " 4.443334,\n",
       " 1.5921144,\n",
       " 0.88859564,\n",
       " 0.15254402,\n",
       " 0.3033616,\n",
       " 0.27711415,\n",
       " -0.11309509,\n",
       " 0.6224386,\n",
       " 1.1018586,\n",
       " 0.16765465,\n",
       " 2.1683767,\n",
       " 1.0782269,\n",
       " 2.640557,\n",
       " 20.856464,\n",
       " 1.0662072,\n",
       " 0.29128444,\n",
       " 4.6045732,\n",
       " 5.659106,\n",
       " 0.4973316,\n",
       " 3.7955673,\n",
       " 2.0392072,\n",
       " 0.46364757,\n",
       " 1.253936,\n",
       " 3.5880315,\n",
       " 6.4411044,\n",
       " 0.32796627,\n",
       " 2.641438,\n",
       " 0.600651,\n",
       " 2.8551648,\n",
       " 3.217547,\n",
       " 0.27197307,\n",
       " 4.9211087,\n",
       " 0.51317906,\n",
       " -0.0393309,\n",
       " 24.605663,\n",
       " -0.068979785,\n",
       " 6.112612,\n",
       " 9.054009,\n",
       " 0.2052533,\n",
       " 0.026678175,\n",
       " 0.76005584,\n",
       " 0.6151643,\n",
       " 1.1721332,\n",
       " 1.0131934,\n",
       " 3.9937482,\n",
       " 0.343066,\n",
       " 6.4040976,\n",
       " 2.9858065,\n",
       " 7.7367144,\n",
       " 0.45373583,\n",
       " 0.07999453,\n",
       " 10.431518,\n",
       " 0.6286854,\n",
       " 0.29061413,\n",
       " 0.46741068,\n",
       " 6.8835154,\n",
       " 0.1505625,\n",
       " 5.4911757,\n",
       " 6.3800583,\n",
       " 0.81776947,\n",
       " 2.0305254,\n",
       " 3.049072,\n",
       " 0.7854623,\n",
       " 5.719866,\n",
       " 3.179054,\n",
       " 3.3135831,\n",
       " 0.4264717,\n",
       " 1.3696074,\n",
       " 1.7929232,\n",
       " 5.130733,\n",
       " -0.032408,\n",
       " 2.1851103,\n",
       " 0.325765,\n",
       " 2.6520112,\n",
       " 0.48125157,\n",
       " 0.5619072,\n",
       " 14.666509,\n",
       " 6.5967984,\n",
       " 2.7047255,\n",
       " 33.165012,\n",
       " 0.22087003,\n",
       " 0.14011073,\n",
       " -0.17238379]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2=[]\n",
    "for i in range(0,100):\n",
    "    y2.append(y1[i][0])\n",
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    if y2[i]<0:\n",
    "        y2[i] = TestData2['time_pre'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"id\":TestData['id'],\"time\":list(y2)}).to_csv('/Users/wyx/Desktop/5001prediction.csv', columns=['id','time'],index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
